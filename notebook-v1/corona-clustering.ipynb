{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "g.pointtext {\n",
    "    display: none;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install country_converter --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from os.path import isfile\n",
    "import numpy as np\n",
    "import country_converter as coco\n",
    "import world_bank_data as wb\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns    \n",
    "import umap.umap_ as umap   ## !pip install 'umap-learn==0.3.10'\n",
    "import hdbscan\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "DEFAULT_PLOTLY_COLORS=['rgb(31, 119, 180)', 'rgb(255, 127, 14)',\n",
    "                       'rgb(44, 160, 44)', 'rgb(214, 39, 40)',\n",
    "                       'rgb(148, 103, 189)', 'rgb(140, 86, 75)',\n",
    "                       'rgb(227, 119, 194)', 'rgb(127, 127, 127)',\n",
    "                       'rgb(188, 189, 34)', 'rgb(23, 190, 207)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseURL = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "fileNamePickle = \"allData.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_demographic_data_of_chinese_provinces():\n",
    "    ## Text file saved from https://en.wikipedia.org/wiki/Provinces_of_China. \n",
    "    file = open('china_population_wiki.tsv', 'r') \n",
    "    lines = []\n",
    "    for i, text in enumerate(file.readlines()):\n",
    "        if i % 3 == 0:\n",
    "            line = ''\n",
    "        line += text.strip()\n",
    "        if i % 3 == 2:\n",
    "            lines = lines + [line.split('\\t')]\n",
    "    df = pd.DataFrame.from_records(lines).iloc[:, [1, 2, 4, 5, 6, 7]]\n",
    "    df.columns = ['ISO', 'Province_Orig', 'Capital', 'Population', 'Density', 'Area']\n",
    "    df.Population = [int(re.sub(',|\\[8\\]', '', p)) for p in df.Population]\n",
    "    df['Province'] = [ \\\n",
    "        re.sub(\"Province.*|Municipality.*|Autonomous.*|Zhuang.*|Special.*|Hui|Uyghur\", \"\", s).strip() \\\n",
    "        for s in df['Province_Orig']]\n",
    "    return df.sort_values('Province')\n",
    "\n",
    "def add_global_population(data):\n",
    "    d = data.copy()\n",
    "    ## Global Population from World Bank.\n",
    "    pop_GLO = wb.get_series('SP.POP.TOTL', date='2018', id_or_value='id', simplify_index=True)\n",
    "    countries = d['Country'].unique()\n",
    "    IOS3_codes = coco.convert(list(countries), to='ISO3')\n",
    "    ISO3_map = dict(zip(countries, IOS3_codes))\n",
    "    d.insert(4, 'Population', \\\n",
    "        [pop_GLO[c] if c in pop_GLO else 0 for c in [ISO3_map[country] for country in d.Country]]\n",
    "    )\n",
    "    ## Chinese provinces from Wiki.\n",
    "    pop_CHI = read_demographic_data_of_chinese_provinces().set_index('Province')['Population']\n",
    "    ind = (d.Country == 'China') & (d.State != '<all>')\n",
    "    d.loc[ind, 'Population'] = [pop_CHI[p] if p in pop_CHI else 0 for p in d.loc[ind, 'State']]\n",
    "    return d\n",
    "\n",
    "def loadData_GLOB(fileName, columnName): \n",
    "    agg_dict = { columnName:sum, 'Lat':np.median, 'Long':np.median }\n",
    "    data = pd.read_csv(baseURL + fileName) \\\n",
    "             .rename(columns={ 'Country/Region':'Country', 'Province/State':'State' }) \\\n",
    "             .melt(id_vars=['Country', 'State', 'Lat', 'Long'], var_name='date', value_name=columnName) \\\n",
    "             .astype({'date':'datetime64[ns]', columnName:'Int64'}, errors='ignore')\n",
    "    ## Extract chinese provinces separately.\n",
    "    data_CHI = data[data.Country == 'China']\n",
    "    data = data.groupby(['Country', 'date']).agg(agg_dict).reset_index()\n",
    "    data.loc[data.Country == 'Denmark', 'Lat'] = 56.2639\n",
    "    data.loc[data.Country == 'Denmark', 'Long'] = 9.5018\n",
    "    data.loc[data.Country == 'France', 'Lat'] = 46.2276\n",
    "    data.loc[data.Country == 'France', 'Long'] = 2.2137\n",
    "    data.loc[data.Country == 'Netherlands', 'Lat'] = 52.1326\n",
    "    data.loc[data.Country == 'Netherlands', 'Long'] = 5.2913\n",
    "    data.loc[data.Country == 'United Kingdom', 'Lat'] = 55.3781\n",
    "    data.loc[data.Country == 'United Kingdom', 'Long'] = -3.4360\n",
    "    data['State'] = '<all>'\n",
    "    return pd.concat([data, data_CHI])\n",
    "\n",
    "## JHU data includes the population within the deaths file, only.\n",
    "def loadData_US(fileName, columnName, addPopulation=False): \n",
    "    id_vars=['Country', 'State', 'Lat', 'Long']\n",
    "    agg_dict = { columnName:sum, 'Lat':np.median, 'Long':np.median }\n",
    "    if addPopulation:\n",
    "        id_vars.append('Population')\n",
    "        agg_dict['Population'] = sum \n",
    "    data = pd.read_csv(baseURL + fileName).iloc[:, 6:] \\\n",
    "             .drop('Combined_Key', axis=1) \\\n",
    "             .rename(columns={ 'Country_Region':'Country', 'Province_State':'State', 'Long_':'Long' }) \\\n",
    "             .melt(id_vars=id_vars, var_name='date', value_name=columnName) \\\n",
    "             .astype({'date':'datetime64[ns]', columnName:'Int64'}, errors='ignore') \\\n",
    "             .groupby(['Country', 'State', 'date']).agg(agg_dict).reset_index()\n",
    "    return data\n",
    "\n",
    "def refreshData():\n",
    "    data_GLOB = loadData_GLOB(\"time_series_covid19_confirmed_global.csv\", \"CumConfirmed\") \\\n",
    "        .merge(loadData_GLOB(\"time_series_covid19_deaths_global.csv\", \"CumDeaths\"))\n",
    "    data_GLOB = add_global_population(data_GLOB)\n",
    "    data_US = loadData_US(\"time_series_covid19_confirmed_US.csv\", \"CumConfirmed\") \\\n",
    "        .merge(loadData_US(\"time_series_covid19_deaths_US.csv\", \"CumDeaths\", addPopulation=True))\n",
    "    data = pd.concat([data_GLOB, data_US])\n",
    "    data.to_pickle(fileNamePickle)\n",
    "    return data\n",
    "\n",
    "def allData():\n",
    "    if not isfile(fileNamePickle):\n",
    "        refreshData()\n",
    "    allData = pd.read_pickle(fileNamePickle)\n",
    "    return allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_mean(values):\n",
    "    return np.exp(np.mean(np.log(values)))\n",
    "\n",
    "def geometric_simple_moving_average(df, len=7):\n",
    "    return df.apply(np.log).rolling(len).mean().apply(np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_zeros(df_column):\n",
    "    ind = np.where(df_column[1:] == 0.0)[0] + 1  # Ignore first value (<NA>).\n",
    "    for i in ind[ind < df_column.size - 1]:\n",
    "        df_column.iloc[i] = df_column.iloc[i+1] = 0.5 * df_column.iloc[i+1]\n",
    "    return df_column\n",
    "\n",
    "def prepare_data(df):\n",
    "    df_cum_cases = df.select_dtypes(include='Int64').astype('float')\n",
    "    df_new_cases = df_cum_cases.diff()  # 1st row is <NA>. \n",
    "    df_new_cases = df_new_cases.apply(fix_zeros)\n",
    "    df_cum_cases = df_new_cases.cumsum()\n",
    "    df_new_cases.columns = [column.replace('Cum', 'New') for column in df_new_cases.columns]\n",
    "    df_all = df_cum_cases.join(df_new_cases)\n",
    "    df_GMA7 = geometric_simple_moving_average(df_all, len=7)\n",
    "    return df_cum_cases, df_new_cases, df_all, df_GMA7\n",
    "\n",
    "def get_conditional_date(ind, df):\n",
    "    if len(ind) == 0:\n",
    "        ind = np.nan\n",
    "        date = np.nan\n",
    "        days_since = np.nan\n",
    "    else:\n",
    "        ind = ind[0]\n",
    "        date = df.iloc[ind]['date']\n",
    "        days_since = (datetime.now() - date).days\n",
    "    return ind, date, days_since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    if df.size < 29+7:\n",
    "        return { }\n",
    "    ## Remove last row if it seems broken (confirmed cases dropped by >80%).\n",
    "    if df.iloc[-1]['CumConfirmed'] < 0.20 * df.iloc[-2]['CumConfirmed']:\n",
    "        df = df[:-1]\n",
    "    last = df.iloc[-1]\n",
    "    df_cum_cases, df_new_cases, df_all, df_GMA7 = prepare_data(df)\n",
    "    ## Index of Outbreak Date (cases > 100/20M).\n",
    "    ind_outbreak, date_outbreak, days_since_outbreak = get_conditional_date(np.where(df_cum_cases.CumConfirmed / df.Population > 5 / 1E6)[0], df)\n",
    "    ## Index of Outbreak Date (cases > 1000/20M).\n",
    "    ind_10X, date_10X, _ = get_conditional_date(np.where(df_cum_cases.CumConfirmed / df.Population > 50 / 1E6)[0], df)\n",
    "    ## Index of Peak week.\n",
    "    ind_peak = np.argmax(df_GMA7.NewDeaths)\n",
    "    date_peak = df.iloc[ind_peak]['date']\n",
    "    ## Early Motality.\n",
    "    earlyMortality = df_GMA7.NewDeaths.iloc[ind_outbreak + 17] / df_GMA7.NewConfirmed.iloc[ind_outbreak + 3] \\\n",
    "        if (df_GMA7.shape[0] > ind_outbreak + 17) else np.nan\n",
    "    earlyAcceleration = \\\n",
    "        (df_GMA7.NewConfirmed.iloc[ind_outbreak + 17] / df_GMA7.NewConfirmed.iloc[ind_outbreak] + 10) / \\\n",
    "        (df_GMA7.NewConfirmed.iloc[ind_outbreak + 10] / df_GMA7.NewConfirmed.iloc[ind_outbreak] + 3) \\\n",
    "        if (df_GMA7.shape[0] > ind_outbreak + 17) else np.nan\n",
    "    newConf_W0toW2 = df_GMA7.NewConfirmed.iloc[-1] / df_GMA7.NewConfirmed.iloc[-15]\n",
    "    newConf_W2toW4 = df_GMA7.NewConfirmed.iloc[-15] / df_GMA7.NewConfirmed.iloc[-29]\n",
    "    return {\n",
    "        'Population':last.Population,\n",
    "        'OutbreakDate':date_outbreak,\n",
    "        'DaysSinceOutbreak':days_since_outbreak, \n",
    "        'DaysSincePeak':(datetime.now() - date_peak).days,\n",
    "        'DaysTo10X':ind_10X - ind_outbreak,\n",
    "        'CasesPerMillion':last.CumConfirmed / last.Population * 1E6,\n",
    "        'DeathsPerMillion':last.CumDeaths / last.Population * 1E6,\n",
    "        'PeakMortality':df_GMA7.NewDeaths.iloc[ind_peak] / df_GMA7.NewConfirmed.iloc[ind_peak - 14],\n",
    "        'EarlyMortality':earlyMortality,\n",
    "        'EarlyAccel':earlyAcceleration,\n",
    "        'NewConf_W0toW2':newConf_W0toW2,\n",
    "        'NewConf_W2toW4':newConf_W2toW4,\n",
    "        'CurrentAccel':newConf_W0toW2 / newConf_W2toW4\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load COVID-19 data from JHU.\n",
    "data = allData()[['Country', 'State', 'date', 'Lat', 'Long', 'Population', 'CumConfirmed', 'CumDeaths']]\n",
    "#data = data[data['Country'].isin(['Italy', 'France', 'Turkey', 'Netherlands', 'Germany', 'Austria'])]\n",
    "\n",
    "## Collect countries for UI elements.\n",
    "countries = data['Country'].unique()\n",
    "countries.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.date == '2020-04-11') & (data.Population > 1E6)].sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Calculate features.\n",
    "features = data.groupby(['Country', 'State']).apply(get_features)\n",
    "features = pd.DataFrame(list(features), index=features.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add region (country+state):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['Region'] = features.index.get_level_values('Country')\n",
    "is_region = (features.index.get_level_values('State') != '<all>')\n",
    "features.loc[is_region, 'Region'] = features.index.get_level_values('Country')[is_region] + ':' + \\\n",
    "    features.index.get_level_values('State')[is_region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[features.index.get_level_values('Country') == 'US'].sort_values(\"DeathsPerMillion\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Bar Chart: Death per Million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = features[features.Population >= 1E6].sort_values('DeathsPerMillion', ascending=False).head(25)\n",
    "colors = ['crimson' if s=='<all>' else 'lightgrey' for s in d.index.get_level_values('State')]\n",
    "go.Figure([go.Bar(\n",
    "    x=d.Region, y=d.DeathsPerMillion,\n",
    "    text=round(d.DeathsPerMillion),\n",
    "    marker_color=colors,\n",
    "    textposition='auto',\n",
    ")]).update_layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', \n",
    "    width=1000, height=700,\n",
    "    font=dict(family=\"Courier New, monospace\", size=22),\n",
    "    title_text='Deaths per Million Population'\n",
    ").show(displayModeBar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lombardia\n",
    "10621 / 10.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Subset of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xlim = 45\n",
    "data_plot = features.merge(data, how='left').sort_values(['Region', 'date'])\n",
    "data_plot['days'] = (data_plot.date - data_plot.OutbreakDate).dt.days\n",
    "data_plot = data_plot[(data_plot.days >= 0) & (data_plot.days <= xlim)]\n",
    "data_plot.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(data, lwd_country=2, lwd_state=2, showlegend=False):\n",
    "    fig = go.Figure()\n",
    "    sorted_regions = data.groupby('Region').last().sort_values('CasesPerMillion').index\n",
    "    for region in sorted_regions:\n",
    "        if (region == 'Germany') | (region == 'US:New York'):\n",
    "            textpos = 'bottom center'\n",
    "        elif region == 'Netherlands':\n",
    "            textpos = 'top center'\n",
    "        else:\n",
    "            textpos = \"top center\"\n",
    "        d = data[(data.Region == region)]\n",
    "        n = (d.shape[0] - 1)\n",
    "        line_width = lwd_country if d.iloc[0]['State'] == '<all>' else lwd_state\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=d.days, y=d.CumConfirmed / d.Population * 1E6, \n",
    "            mode='lines+text+markers', name=region, \n",
    "            marker={ 'size': [0] * n + [6] },\n",
    "            line={ 'width':line_width },\n",
    "            text=[\"\"] * n + [region], textposition=textpos, textfont_size=13\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "        legend={ 'traceorder':'reversed', 'font':{ 'size':13 } },\n",
    "        paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', \n",
    "        font=dict(family=\"Courier New, monospace\", size=18),\n",
    "        width=1000, height=750,\n",
    "        showlegend=showlegend,\n",
    "        title='Cumulated Number of COVID-19 Cases since Outbreak',\n",
    "        xaxis_title='Days since Outbreak (= more than 5 cases per million)', yaxis_type=\"log\",\n",
    "        yaxis_title='Cumulated Confirmed Cases per Million') \\\n",
    "   .update_xaxes(showline=True, linewidth=2, gridcolor='lightgrey', range=[0, xlim*1.1]) \\\n",
    "   .update_yaxes(showline=True, linewidth=2, gridcolor='lightgrey') \\\n",
    "   .show(displayModeBar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "g.pointtext {\n",
    "    display: none;\n",
    "    traceorder: reversed;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(data_plot[\n",
    "    (data_plot.Population > 15E6) & (data_plot.CasesPerMillion > 50) & (data_plot.State == '<all>')\n",
    "], showlegend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(data_plot[\n",
    "    (data_plot.Country =='US') & (data_plot.State != '<all>') &\n",
    "    (data_plot.Population > 5.0E6) ##& (data_plot.CasesPerMillion > 50)\n",
    "], showlegend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(features, names=['DaysTo10X', 'EarlyMortality', 'EarlyAccel']):\n",
    "    d = features[names + ['Region']].set_index('Region')\n",
    "    d = d.replace([np.inf, -np.inf], np.nan)\n",
    "    d = d.dropna()\n",
    "    return d\n",
    "\n",
    "## Read https://umap-learn.readthedocs.io/en/latest/clustering.html\n",
    "def plot_umap_with_clusters(d, random_state=7):\n",
    "    standard_embedding = umap.UMAP(random_state=random_state\n",
    "    ).fit_transform(d)\n",
    "    \n",
    "    clusterable_embedding = umap.UMAP(random_state=random_state, min_dist=0.0, n_neighbors=10,\n",
    "    ).fit_transform(d)\n",
    "    \n",
    "    labels = hdbscan.HDBSCAN(min_samples=2, min_cluster_size=5,\n",
    "    ).fit_predict(clusterable_embedding)\n",
    "    \n",
    "    clustered = (labels >= 0)\n",
    "    print(np.unique(labels, return_counts=True))\n",
    "    \n",
    "    go.Figure() \\\n",
    "    .add_trace(go.Scatter(\n",
    "        x=standard_embedding[:,0], y=standard_embedding[:,1],\n",
    "        mode='text+markers', text=[r for r in d.index], \n",
    "        marker={ 'color':[DEFAULT_PLOTLY_COLORS[c] for c in labels[clustered]] },\n",
    "        textposition=\"top center\",\n",
    "    )) \\\n",
    "    .update_layout(\n",
    "        paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', \n",
    "        font=dict(family=\"Courier New, monospace\", size=15),\n",
    "        width=1000, height=750,\n",
    "        title='UMAP projection of the COVID-19 Outbreak Data',\n",
    "        xaxis_title='', yaxis_title='') \\\n",
    "    .update_xaxes(showline=True, linewidth=2, gridcolor='lightgrey') \\\n",
    "    .update_yaxes(showline=True, linewidth=2, gridcolor='lightgrey') \\\n",
    "    .show(displayModeBar=False) \n",
    "    return labels\n",
    "        \n",
    "def make_violin_plots(d, labels, rows=1):\n",
    "    fig = make_subplots(rows=rows, cols=3, subplot_titles=d.columns)\n",
    "    for i, name in enumerate(d.columns):\n",
    "        for label in np.unique(labels):\n",
    "            ind = (labels == label)\n",
    "            fig.add_trace(\n",
    "                go.Violin(\n",
    "                    y=d.loc[ind, name], box_visible=True, line_color=DEFAULT_PLOTLY_COLORS[label], \n",
    "                    name=\"Class \" + str(label)\n",
    "                ), row=int(i/3) + 1, col=(i % 3) + 1\n",
    "            )\n",
    "    fig.update_layout(\n",
    "        paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', \n",
    "        font=dict(family=\"Courier New, monospace\", size=15),\n",
    "        width=1200, height=1000, showlegend=False) \\\n",
    "    .update_yaxes(showline=False, linewidth=0) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([25, 50, 100, 200, 400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering of Outbreak Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP Projection with HDFSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = get_features(features, names=['DaysTo10X', 'EarlyMortality', 'EarlyAccel'])\n",
    "labels = plot_umap_with_clusters(f, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_violin_plots(f, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering of Overall Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP Projection with HDFSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = get_features(features, names=['DaysTo10X', 'EarlyMortality', 'PeakMortality', 'EarlyAccel', 'CurrentAccel'])\n",
    "labels = plot_umap_with_clusters(f, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_violin_plots(f, labels, rows=2)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
